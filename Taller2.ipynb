{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto buscador de palabras con MongoDB Taller 2\n",
    "\n",
    "Authors: \n",
    "Yurany Cortés Rosero\n",
    "María Fernanda Otalora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realiza la conexión a la BD en servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def conexionBD():\n",
    "    #Conexion a la base de datos\n",
    "    client = MongoClient()\n",
    "    client = pymongo.MongoClient(\"mongodb://testAdmin:12345@104.200.28.188:27017/buscador\")\n",
    "    db = client.buscador\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se lee el archivo inicial, se le quitan stopwords, \n",
    "### caracteres especiales y se guarda en la base de datos en la coleccion documentos, \n",
    "### la coleccion raw guarda los documentos como inicialmente se leen sin tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 0.015624046325683594 -----------\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import bson\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from Documentos import Documentos\n",
    "from collections import Counter\n",
    "from Diccionario import Diccionario\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "db = conexionBD()\n",
    "#Obtenemos las colecciones para trabajar y guardar la informacion\n",
    "collDocumentos   = db.documentos\n",
    "collRaw          = db.raw\n",
    "collDic          = db.diccionario\n",
    "collMatrizTF     = db.matriztf\n",
    "collDenominador  = db.denominador\n",
    "collLogTermin    = db.logtermin\n",
    "\n",
    "#Obtenemos los stopwords\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close() \n",
    "\n",
    "def tomarDocumentos():\n",
    "    \n",
    "    pattern = re.compile(r'\\W+')\n",
    "\n",
    "    #Preparamos los datos a guardar, se utiliza el ejemplo de archivos\n",
    "    archivo = open(\"archivosinicial/reut2-001.sgm\", \"r\")\n",
    "    soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "    archivo.close()\n",
    "\n",
    "    documentos = []\n",
    "    documentos = soup1.find_all('reuters')\n",
    "    \n",
    "    #Obtener la informacion de los archivos\n",
    "    jsonDocumento = [0 for x in range(len(documentos))]\n",
    "    jsonRaw       = [0 for x in range(len(documentos))]\n",
    "\n",
    "\n",
    "    for i in range(len(documentos)):\n",
    "        try:        \n",
    "            cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "            cadena = cadena.lower()\n",
    "            cadena = cadena.replace(' reuter','')\n",
    "            cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "            for j in range(len(words)):             \n",
    "                cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)                    \n",
    "            collDocumentos.insert_one({\"_id\":i,\"documento\":cadena})            \n",
    "            cadena=documentos[i].title.string + \"@@\"+ documentos[i].body.string \n",
    "            collRaw.insert_one({\"_id\":i,\"documento\":cadena})            \n",
    "        except:\n",
    "            pass\n",
    "      \n",
    "        \n",
    "#tomarDocumentos()  \n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se guarda el diccionario en la base de datos en la coleccion diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiccionario():\n",
    "    cadena =\"\"\n",
    "    cursor = collDocumentos.find()\n",
    "    for fut in cursor:\n",
    "        cadena = cadena+\" \"+fut['documento']\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    dictionary = pattern.split(cadena)\n",
    "    dictionary = sorted(list(set(dictionary)))\n",
    "    dictionary.remove(\"\")    \n",
    "\n",
    "    #se guarda el diccionario en la coleccion diccionario.\n",
    "    for i in range(len(dictionary)):          \n",
    "        idDic = collDic.insert_one({\"_id\":i,\"word\":dictionary[i]}).inserted_id    \n",
    "\n",
    "    print(\"Termino Diccionario\")\n",
    "#getDiccionario()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la matriztf y el denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 0.15219926834106445 -----------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF():\n",
    "    \n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "\n",
    "    denominador=[0 for x in range(longDic)]\n",
    "    \n",
    "    cursorDoc = collDocumentos.find()    \n",
    "    for fut in cursorDoc:            \n",
    "        cursorDic = collDic.find()\n",
    "        for dic in cursorDic:                                                 \n",
    "            patron = re.compile(r''+dic['word']+'')        \n",
    "            count = len(patron.findall(fut['documento']))            \n",
    "            collMatrizTF.insert_one({\"idDoc\":fut['_id'],\"idword\":dic['_id'],\"cant\":count})\n",
    "            \n",
    "            if count > 0:                        \n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+1\n",
    "            else:\n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+0\n",
    "\n",
    "    \n",
    "    for i in range(len(denominador)):\n",
    "        collDenominador.insert_one({\"_id\":i,\"cantDocWord\":denominador[i]})      \n",
    "        \n",
    "    print(\"Termino TF\")    \n",
    "            \n",
    "#setMatrizTF()\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la matriz tfidf e indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termino TFIDF\n",
      " ------ Tiempo de ejecucion 0.2685115337371826 -----------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "collTFIDF = db.collectiontfidf\n",
    "collIndIn = db.collectionindinv\n",
    "\n",
    "\n",
    "def getMatrizTFIDF():\n",
    "    \n",
    "    #Obtenemos cursorDoc, para realizar el calculo\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    \n",
    "    #Obtenemos tamaño del diccionario\n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "    \n",
    "    indiceInv = [0 for x in range(longDic)]\n",
    "    \n",
    "    cursorTF  = collMatrizTF.find()\n",
    "    for tf in cursorTF:     \n",
    "        cursorDen = collDenominador.find({\"_id\":{\"$in\":[tf['idword']]}})\n",
    "        for cur in cursorDen:                    \n",
    "            logTerm = math.log(cantDoc/cur['cantDocWord'])\n",
    "            tfidf = tf['cant']*logTerm           \n",
    "            collTFIDF.insert_one({\"idDoc\":tf['idDoc'],\"idWord\":tf['idword'],\"tfidf\":tfidf})\n",
    "                        \n",
    "            if(tf['cant']>0):    \n",
    "                indiceInv[tf['idword']] = str(indiceInv[tf['idword']]) +\"|\"+str(tf['idDoc'])\n",
    "                \n",
    "    \n",
    "    for i in range(len(indiceInv)):\n",
    "        docs = indiceInv[i].split(\"|\")                \n",
    "        documentos=[]\n",
    "        for j in range(len(docs)):            \n",
    "            if(j>0):\n",
    "                documentos.append(docs[j])\n",
    "        collIndIn.insert_one({\"idword\":i,\"documentos\":[documentos]})\n",
    "#getMatrizTFIDF()\n",
    "\n",
    "#print(\"Indice Invertido\")\n",
    "#col2 = collIndIn.find(\n",
    "#for cur2 in  col2:\n",
    "    #print(cur2)\n",
    "#print(\"Tfidf\")\n",
    "#col2 = collTFIDF.find()\n",
    "#for cur2 in  col2:\n",
    "#   print(cur2)\n",
    "\n",
    "\n",
    "    \n",
    "print(\"Termino TFIDF\")        \n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de similitud de coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimilitudCoseno(VectorArchivo, vectorBusqueda):\n",
    "    x = np.array(VectorArchivo)\n",
    "    y = np.array(vectorBusqueda)\n",
    "    dot = np.dot(x,y)\n",
    "    x_modulus = np.sqrt((x*x).sum())\n",
    "    y_modulus = np.sqrt((y*y).sum())\n",
    "    similitud=0\n",
    "    if(x_modulus != 0 and y_modulus != 0 ):\n",
    "        similitud = dot / x_modulus / y_modulus\n",
    "    return similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir la funcion para realizar la busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buscar(cadena):   \n",
    "\n",
    "    cadena = cadena.lower()\n",
    "    cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "    for j in range(len(words)):             \n",
    "        cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)     \n",
    "   \n",
    "    resultadosBusqueda= []\n",
    "    listIdWords=[]\n",
    "    NumTerms=db.diccionario.count()\n",
    "    #cantidad de documentos\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    idDoc=[]\n",
    "    #Tomamos cada palabra ingresada en la busqueda\n",
    "    listaPalabras=Counter(cadena.split(\" \"))\n",
    "    vecBusqueda=np.zeros(NumTerms)\n",
    "    for WordF in listaPalabras.most_common():\n",
    "        num=WordF[1]  \n",
    "        findWord=db.diccionario.find_one({'word':WordF[0]})\n",
    "        if(findWord!= None):\n",
    "            IdWord=findWord['_id']\n",
    "            denom= collDenominador.find_one({\"_id\":{\"$in\":[IdWord]}})\n",
    "            valorDenom=denom['cantDocWord']\n",
    "            logTerm = math.log(cantDoc/valorDenom)\n",
    "            tfidfBusqueda=num*logTerm\n",
    "            vecBusqueda[IdWord]=tfidfBusqueda\n",
    "            if(num>0):\n",
    "                listIdWords.append(IdWord)\n",
    "    \n",
    "    tfidf=[]\n",
    "        \n",
    "    if(len(listIdWords)>0):\n",
    "        #Se busca con el indice invertido los documentos que tienen las palabras a buscar\n",
    "        IdDocuments= db.collectionindinv.find_one({'idword':listIdWords[0]})['documentos'][0]\n",
    "        for countWord in range(1,len(listIdWords)):\n",
    "            for IdDoc in db.collectionindinv.find_one({'idword':listIdWords[countWord]})['documentos'][0]:                   \n",
    "                if(IdDoc not in IdDocuments):\n",
    "                    IdDocuments.append(IdDoc)   \n",
    "     \n",
    "        countArchivos=0 \n",
    "        for IdDocument in IdDocuments:\n",
    "            VectorTfidf=[]\n",
    "            \n",
    "            for tfidfa in db.collectiontfidf.find({'idDoc':int(IdDocument)}):\n",
    "                \n",
    "                VectorTfidf.append(tfidfa['tfidf']) \n",
    "            resultadosBusqueda.append([])\n",
    "            similitud = SimilitudCoseno(VectorTfidf, vecBusqueda)\n",
    "           \n",
    "            resultadosBusqueda[countArchivos].append(IdDocument)\n",
    "            resultadosBusqueda[countArchivos].append(similitud)\n",
    "            countArchivos+=1\n",
    "        \n",
    "        resultadosBusqueda = sorted(resultadosBusqueda, key=lambda a_entry: a_entry[1],reverse=True)\n",
    "       \n",
    "        for resultado in resultadosBusqueda:\n",
    "           \n",
    "            idDoc=resultado[0]\n",
    "            docdb= db.raw.find_one({\"_id\": int(idDoc)})\n",
    "           \n",
    "            doc=docdb['documento']\n",
    "            docVec=doc.split(\"@@\")\n",
    "           \n",
    "            display(HTML('<h1>'+docVec[0]+'</h1>'))\n",
    "            display(HTML('<p>'+docVec[1]+'</p>'))\n",
    "       \n",
    "    # se imprime el diccionario\n",
    "    print(\"Se imprime el diccionario \")\n",
    "    dic = db.diccionario.find()\n",
    "    for cur2 in  dic:\n",
    "         print(cur2)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Función que lanza la ventana para el ingreso de las palabras a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se imprime el diccionario \n",
      "{'_id': 0, 'word': 'acceptance'}\n",
      "{'_id': 1, 'word': 'accounting'}\n",
      "{'_id': 2, 'word': 'acquired'}\n",
      "{'_id': 3, 'word': 'addition'}\n",
      "{'_id': 4, 'word': 'adjustments'}\n",
      "{'_id': 5, 'word': 'afternoon'}\n",
      "{'_id': 6, 'word': 'ag'}\n",
      "{'_id': 7, 'word': 'ago'}\n",
      "{'_id': 8, 'word': 'aim'}\n",
      "{'_id': 9, 'word': 'aircraft'}\n",
      "{'_id': 10, 'word': 'allowed'}\n",
      "{'_id': 11, 'word': 'amr'}\n",
      "{'_id': 12, 'word': 'announced'}\n",
      "{'_id': 13, 'word': 'appreciation'}\n",
      "{'_id': 14, 'word': 'arrange'}\n",
      "{'_id': 15, 'word': 'asked'}\n",
      "{'_id': 16, 'word': 'assistance'}\n",
      "{'_id': 17, 'word': 'associations'}\n",
      "{'_id': 18, 'word': 'assumed'}\n",
      "{'_id': 19, 'word': 'august'}\n",
      "{'_id': 20, 'word': 'avg'}\n",
      "{'_id': 21, 'word': 'band'}\n",
      "{'_id': 22, 'word': 'bank'}\n",
      "{'_id': 23, 'word': 'banking'}\n",
      "{'_id': 24, 'word': 'bills'}\n",
      "{'_id': 25, 'word': 'bnl'}\n",
      "{'_id': 26, 'word': 'bond'}\n",
      "{'_id': 27, 'word': 'boston'}\n",
      "{'_id': 28, 'word': 'bought'}\n",
      "{'_id': 29, 'word': 'brings'}\n",
      "{'_id': 30, 'word': 'business'}\n",
      "{'_id': 31, 'word': 'capital'}\n",
      "{'_id': 32, 'word': 'central'}\n",
      "{'_id': 33, 'word': 'chairman'}\n",
      "{'_id': 34, 'word': 'chang'}\n",
      "{'_id': 35, 'word': 'charges'}\n",
      "{'_id': 36, 'word': 'cheng'}\n",
      "{'_id': 37, 'word': 'chi'}\n",
      "{'_id': 38, 'word': 'chief'}\n",
      "{'_id': 39, 'word': 'coal'}\n",
      "{'_id': 40, 'word': 'commercial'}\n",
      "{'_id': 41, 'word': 'company'}\n",
      "{'_id': 42, 'word': 'compared'}\n",
      "{'_id': 43, 'word': 'compares'}\n",
      "{'_id': 44, 'word': 'comprising'}\n",
      "{'_id': 45, 'word': 'consortium'}\n",
      "{'_id': 46, 'word': 'continued'}\n",
      "{'_id': 47, 'word': 'convertible'}\n",
      "{'_id': 48, 'word': 'corp'}\n",
      "{'_id': 49, 'word': 'coupon'}\n",
      "{'_id': 50, 'word': 'credit'}\n",
      "{'_id': 51, 'word': 'currency'}\n",
      "{'_id': 52, 'word': 'cut'}\n",
      "{'_id': 53, 'word': 'dai'}\n",
      "{'_id': 54, 'word': 'davis'}\n",
      "{'_id': 55, 'word': 'deliveries'}\n",
      "{'_id': 56, 'word': 'details'}\n",
      "{'_id': 57, 'word': 'discontinued'}\n",
      "{'_id': 58, 'word': 'dlr'}\n",
      "{'_id': 59, 'word': 'dlrs'}\n",
      "{'_id': 60, 'word': 'dollar'}\n",
      "{'_id': 61, 'word': 'earlier'}\n",
      "{'_id': 62, 'word': 'early'}\n",
      "{'_id': 63, 'word': 'engines'}\n",
      "{'_id': 64, 'word': 'england'}\n",
      "{'_id': 65, 'word': 'enter'}\n",
      "{'_id': 66, 'word': 'equal'}\n",
      "{'_id': 67, 'word': 'equity'}\n",
      "{'_id': 68, 'word': 'er'}\n",
      "{'_id': 69, 'word': 'exchange'}\n",
      "{'_id': 70, 'word': 'exchanges'}\n",
      "{'_id': 71, 'word': 'excludes'}\n",
      "{'_id': 72, 'word': 'exercise'}\n",
      "{'_id': 73, 'word': 'exporters'}\n",
      "{'_id': 74, 'word': 'extraordinary'}\n",
      "{'_id': 75, 'word': 'fall'}\n",
      "{'_id': 76, 'word': 'far'}\n",
      "{'_id': 77, 'word': 'february'}\n",
      "{'_id': 78, 'word': 'federation'}\n",
      "{'_id': 79, 'word': 'fertiliser'}\n",
      "{'_id': 80, 'word': 'figures'}\n",
      "{'_id': 81, 'word': 'firms'}\n",
      "{'_id': 82, 'word': 'fix'}\n",
      "{'_id': 83, 'word': 'forecast'}\n",
      "{'_id': 84, 'word': 'foreign'}\n",
      "{'_id': 85, 'word': 'form'}\n",
      "{'_id': 86, 'word': 'forma'}\n",
      "{'_id': 87, 'word': 'franc'}\n",
      "{'_id': 88, 'word': 'fsi'}\n",
      "{'_id': 89, 'word': 'future'}\n",
      "{'_id': 90, 'word': 'gain'}\n",
      "{'_id': 91, 'word': 'gains'}\n",
      "{'_id': 92, 'word': 'ge'}\n",
      "{'_id': 93, 'word': 'given'}\n",
      "{'_id': 94, 'word': 'government'}\n",
      "{'_id': 95, 'word': 'governor'}\n",
      "{'_id': 96, 'word': 'grease'}\n",
      "{'_id': 97, 'word': 'guarantees'}\n",
      "{'_id': 98, 'word': 'halt'}\n",
      "{'_id': 99, 'word': 'help'}\n",
      "{'_id': 100, 'word': 'herbicides'}\n",
      "{'_id': 101, 'word': 'hold'}\n",
      "{'_id': 102, 'word': 'holding'}\n",
      "{'_id': 103, 'word': 'holdings'}\n",
      "{'_id': 104, 'word': 'hong'}\n",
      "{'_id': 105, 'word': 'hotel'}\n",
      "{'_id': 106, 'word': 'ichi'}\n",
      "{'_id': 107, 'word': 'include'}\n",
      "{'_id': 108, 'word': 'income'}\n",
      "{'_id': 109, 'word': 'increases'}\n",
      "{'_id': 110, 'word': 'indicated'}\n",
      "{'_id': 111, 'word': 'initial'}\n",
      "{'_id': 112, 'word': 'institutional'}\n",
      "{'_id': 113, 'word': 'insurance'}\n",
      "{'_id': 114, 'word': 'intent'}\n",
      "{'_id': 115, 'word': 'investment'}\n",
      "{'_id': 116, 'word': 'investors'}\n",
      "{'_id': 117, 'word': 'issue'}\n",
      "{'_id': 118, 'word': 'issues'}\n",
      "{'_id': 119, 'word': 'italy'}\n",
      "{'_id': 120, 'word': 'japan'}\n",
      "{'_id': 121, 'word': 'joint'}\n",
      "{'_id': 122, 'word': 'kong'}\n",
      "{'_id': 123, 'word': 'korea'}\n",
      "{'_id': 124, 'word': 'largest'}\n",
      "{'_id': 125, 'word': 'lead'}\n",
      "{'_id': 126, 'word': 'led'}\n",
      "{'_id': 127, 'word': 'letter'}\n",
      "{'_id': 128, 'word': 'level'}\n",
      "{'_id': 129, 'word': 'listing'}\n",
      "{'_id': 130, 'word': 'local'}\n",
      "{'_id': 131, 'word': 'long'}\n",
      "{'_id': 132, 'word': 'losing'}\n",
      "{'_id': 133, 'word': 'loss'}\n",
      "{'_id': 134, 'word': 'makers'}\n",
      "{'_id': 135, 'word': 'manager'}\n",
      "{'_id': 136, 'word': 'march'}\n",
      "{'_id': 137, 'word': 'market'}\n",
      "{'_id': 138, 'word': 'midcon'}\n",
      "{'_id': 139, 'word': 'mineral'}\n",
      "{'_id': 140, 'word': 'ministry'}\n",
      "{'_id': 141, 'word': 'minstar'}\n",
      "{'_id': 142, 'word': 'money'}\n",
      "{'_id': 143, 'word': 'monkey'}\n",
      "{'_id': 144, 'word': 'months'}\n",
      "{'_id': 145, 'word': 'national'}\n",
      "{'_id': 146, 'word': 'net'}\n",
      "{'_id': 147, 'word': 'nil'}\n",
      "{'_id': 148, 'word': 'note'}\n",
      "{'_id': 149, 'word': 'notes'}\n",
      "{'_id': 150, 'word': 'nov'}\n",
      "{'_id': 151, 'word': 'november'}\n",
      "{'_id': 152, 'word': 'number'}\n",
      "{'_id': 153, 'word': 'obtaining'}\n",
      "{'_id': 154, 'word': 'occidental'}\n",
      "{'_id': 155, 'word': 'offering'}\n",
      "{'_id': 156, 'word': 'officer'}\n",
      "{'_id': 157, 'word': 'officials'}\n",
      "{'_id': 158, 'word': 'oper'}\n",
      "{'_id': 159, 'word': 'operating'}\n",
      "{'_id': 160, 'word': 'operation'}\n",
      "{'_id': 161, 'word': 'operations'}\n",
      "{'_id': 162, 'word': 'order'}\n",
      "{'_id': 163, 'word': 'orders'}\n",
      "{'_id': 164, 'word': 'ordinary'}\n",
      "{'_id': 165, 'word': 'original'}\n",
      "{'_id': 166, 'word': 'output'}\n",
      "{'_id': 167, 'word': 'outright'}\n",
      "{'_id': 168, 'word': 'owned'}\n",
      "{'_id': 169, 'word': 'payment'}\n",
      "{'_id': 170, 'word': 'pct'}\n",
      "{'_id': 171, 'word': 'periods'}\n",
      "{'_id': 172, 'word': 'placing'}\n",
      "{'_id': 173, 'word': 'planned'}\n",
      "{'_id': 174, 'word': 'plans'}\n",
      "{'_id': 175, 'word': 'plea'}\n",
      "{'_id': 176, 'word': 'president'}\n",
      "{'_id': 177, 'word': 'pressure'}\n",
      "{'_id': 178, 'word': 'price'}\n",
      "{'_id': 179, 'word': 'private'}\n",
      "{'_id': 180, 'word': 'pro'}\n",
      "{'_id': 181, 'word': 'produce'}\n",
      "{'_id': 182, 'word': 'production'}\n",
      "{'_id': 183, 'word': 'profit'}\n",
      "{'_id': 184, 'word': 'properties'}\n",
      "{'_id': 185, 'word': 'provided'}\n",
      "{'_id': 186, 'word': 'public'}\n",
      "{'_id': 187, 'word': 'purchase'}\n",
      "{'_id': 188, 'word': 'purchases'}\n",
      "{'_id': 189, 'word': 'qtr'}\n",
      "{'_id': 190, 'word': 'quarter'}\n",
      "{'_id': 191, 'word': 'quoted'}\n",
      "{'_id': 192, 'word': 'rate'}\n",
      "{'_id': 193, 'word': 'realized'}\n",
      "{'_id': 194, 'word': 'reason'}\n",
      "{'_id': 195, 'word': 'received'}\n",
      "{'_id': 196, 'word': 'reeacquisition'}\n",
      "{'_id': 197, 'word': 'rejected'}\n",
      "{'_id': 198, 'word': 'rejects'}\n",
      "{'_id': 199, 'word': 'reponsibilities'}\n",
      "{'_id': 200, 'word': 'representatives'}\n",
      "{'_id': 201, 'word': 'request'}\n",
      "{'_id': 202, 'word': 'resigned'}\n",
      "{'_id': 203, 'word': 'respective'}\n",
      "{'_id': 204, 'word': 'resulting'}\n",
      "{'_id': 205, 'word': 'revised'}\n",
      "{'_id': 206, 'word': 'revs'}\n",
      "{'_id': 207, 'word': 'rise'}\n",
      "{'_id': 208, 'word': 'said'}\n",
      "{'_id': 209, 'word': 'sandoz'}\n",
      "{'_id': 210, 'word': 'saturday'}\n",
      "{'_id': 211, 'word': 'saving'}\n",
      "{'_id': 212, 'word': 'savings'}\n",
      "{'_id': 213, 'word': 'session'}\n",
      "{'_id': 214, 'word': 'share'}\n",
      "{'_id': 215, 'word': 'shareholders'}\n",
      "{'_id': 216, 'word': 'shares'}\n",
      "{'_id': 217, 'word': 'shortage'}\n",
      "{'_id': 218, 'word': 'shrs'}\n",
      "{'_id': 219, 'word': 'signed'}\n",
      "{'_id': 220, 'word': 'singapore'}\n",
      "{'_id': 221, 'word': 'single'}\n",
      "{'_id': 222, 'word': 'size'}\n",
      "{'_id': 223, 'word': 'south'}\n",
      "{'_id': 224, 'word': 'soviet'}\n",
      "{'_id': 225, 'word': 'spokesman'}\n",
      "{'_id': 226, 'word': 'spokeswoman'}\n",
      "{'_id': 227, 'word': 'stake'}\n",
      "{'_id': 228, 'word': 'start'}\n",
      "{'_id': 229, 'word': 'state'}\n",
      "{'_id': 230, 'word': 'stg'}\n",
      "{'_id': 231, 'word': 'stock'}\n",
      "{'_id': 232, 'word': 'stop'}\n",
      "{'_id': 233, 'word': 'subsidiary'}\n",
      "{'_id': 234, 'word': 'suisse'}\n",
      "{'_id': 235, 'word': 'swiss'}\n",
      "{'_id': 236, 'word': 'taiwan'}\n",
      "{'_id': 237, 'word': 'tax'}\n",
      "{'_id': 238, 'word': 'telling'}\n",
      "{'_id': 239, 'word': 'term'}\n",
      "{'_id': 240, 'word': 'terpstra'}\n",
      "{'_id': 241, 'word': 'textile'}\n",
      "{'_id': 242, 'word': 'time'}\n",
      "{'_id': 243, 'word': 'today'}\n",
      "{'_id': 244, 'word': 'total'}\n",
      "{'_id': 245, 'word': 'traded'}\n",
      "{'_id': 246, 'word': 'treasury'}\n",
      "{'_id': 247, 'word': 'twinjets'}\n",
      "{'_id': 248, 'word': 'u'}\n",
      "{'_id': 249, 'word': 'unable'}\n",
      "{'_id': 250, 'word': 'undertaken'}\n",
      "{'_id': 251, 'word': 'uneconomic'}\n",
      "{'_id': 252, 'word': 'union'}\n",
      "{'_id': 253, 'word': 'unspecified'}\n",
      "{'_id': 254, 'word': 'ussr'}\n",
      "{'_id': 255, 'word': 'venture'}\n",
      "{'_id': 256, 'word': 'ventures'}\n",
      "{'_id': 257, 'word': 'view'}\n",
      "{'_id': 258, 'word': 'volksbank'}\n",
      "{'_id': 259, 'word': 'warrants'}\n",
      "{'_id': 260, 'word': 'weedkiller'}\n",
      "{'_id': 261, 'word': 'western'}\n",
      "{'_id': 262, 'word': 'william'}\n",
      "{'_id': 263, 'word': 'worth'}\n",
      "{'_id': 264, 'word': 'writedown'}\n",
      "{'_id': 265, 'word': 'year'}\n",
      "{'_id': 266, 'word': 'years'}\n",
      "{'_id': 267, 'word': 'yen'}\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#Generar la ventana que recibe el texto del buscador\n",
    "vent = Tk()\n",
    "a = StringVar()\n",
    "def valor():\n",
    "    a = entrada.get()    \n",
    "    buscar(a)\n",
    "\n",
    "entrada = Entry(vent, width=30)\n",
    "entrada.grid(row=0, column=0)\n",
    "\n",
    "boton = Button(vent, text=\"Buscar\", command=valor)\n",
    "boton.grid(row=1, column=0)\n",
    "\n",
    "vent.mainloop()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
