{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto buscador de palabras con MongoDB Taller 2\n",
    "\n",
    "## Authors: \n",
    "### Yurany Cortés Rosero\n",
    "### María Fernanda Otalora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realiza la conexión a la BD en servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def conexionBD():\n",
    "    #Conexion a la base de datos\n",
    "    client = MongoClient()\n",
    "    client = pymongo.MongoClient(\"mongodb://testAdmin:12345@104.200.28.188:27017/buscador\")\n",
    "    db = client.buscadorTallerBigData2\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se lee el archivo inicial, se le quitan stopwords, \n",
    "### caracteres especiales y se guarda en la base de datos en la coleccion documentos, \n",
    "### la coleccion raw guarda los documentos como inicialmente se leen sin tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import bson\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from Documentos import Documentos\n",
    "from collections import Counter\n",
    "from Diccionario import Diccionario\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "db = conexionBD()\n",
    "#Obtenemos las colecciones para trabajar y guardar la informacion\n",
    "collDocumentos   = db.documentos\n",
    "collRaw          = db.raw\n",
    "collDic          = db.diccionario\n",
    "collMatrizTF     = db.matriztf\n",
    "collDenominador  = db.denominador\n",
    "collLogTermin    = db.logtermin\n",
    "\n",
    "#Obtenemos los stopwords\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close() \n",
    "\n",
    "def tomarDocumentos():\n",
    "    \n",
    "    pattern = re.compile(r'\\W+')\n",
    "\n",
    "    #Preparamos los datos a guardar, se utiliza el ejemplo de archivos\n",
    "    archivo = open(\"archivosinicial/reut2-001.sgm\", \"r\")\n",
    "    soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "    archivo.close()\n",
    "\n",
    "    documentos = []\n",
    "    documentos = soup1.find_all('reuters')\n",
    "    \n",
    "    #Obtener la informacion de los archivos\n",
    "    jsonDocumento = [0 for x in range(len(documentos))]\n",
    "    jsonRaw       = [0 for x in range(len(documentos))]\n",
    "\n",
    "\n",
    "    for i in range(len(documentos)):\n",
    "        try:        \n",
    "            cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "            cadena = cadena.lower()\n",
    "            cadena = cadena.replace(' reuter','')\n",
    "            cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "            for j in range(len(words)):             \n",
    "                cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)        \n",
    "            jsonDocumento[i] = Documentos(i,cadena)\n",
    "            cadena=documentos[i].title.string + \"@@\"+ documentos[i].body.string \n",
    "            jsonRaw[i] = Documentos(i,cadena)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # Guardamos los objetos documentos en la coleccion inicial    \n",
    "   #for doc in jsonDocumento:\n",
    "      #  collDocumentos.insert_one(doc.toDBCollection())\n",
    "\n",
    "    # Guardamos los objetos documentos en la coleccion raw    \n",
    "   # for doc in jsonRaw:    \n",
    "       # collRaw.insert_one(doc.toDBCollection())\n",
    "#tomarDocumentos()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se guarda el diccionario en la base de datos en la coleccion diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDiccionario():\n",
    "    cadena =\"\"\n",
    "    cursor = collDocumentos.find()\n",
    "    for fut in cursor:\n",
    "        cadena = cadena+\" \"+fut['documento']\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    dictionary = pattern.split(cadena)\n",
    "    dictionary = sorted(list(set(dictionary)))\n",
    "    dictionary.remove(\"\")    \n",
    "\n",
    "    #se guarda el diccionario en la coleccion diccionario.\n",
    "    #for i in range(len(dictionary)):          \n",
    "       # idDic = collDic.insert_one({\"_id\":i,\"word\":dictionary[i]}).inserted_id    \n",
    "\n",
    "    #collDic.delete_one({\"_id\":'+str(i)+'})\n",
    "#getDiccionario()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la matriztf y el denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF():\n",
    "    \n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "\n",
    "    denominador=[0 for x in range(longDic)]\n",
    "    \n",
    "    cursorDoc = collDocumentos.find()    \n",
    "    for fut in cursorDoc:            \n",
    "        cursorDic = collDic.find()\n",
    "        for dic in cursorDic:                                                 \n",
    "            patron = re.compile(r''+dic['word']+'')        \n",
    "            count = len(patron.findall(fut['documento']))            \n",
    "            #collMatrizTF.insert_one({\"idDoc\":fut['_id'],\"idword\":dic['_id'],\"cant\":count})\n",
    "            \n",
    "            if count > 0:                        \n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+1\n",
    "            else:\n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+0\n",
    "\n",
    "    \n",
    "    #for i in range(len(denominador)):\n",
    "        #collDenominador.insert_one({\"_id\":i,\"cantDocWord\":denominador[i]})        \n",
    "            \n",
    "#setMatrizTF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la matriz tfidf e indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 0.33300161361694336 -----------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "collTFIDF = db.collectiontfidf\n",
    "collIndIn = db.collectionindinv\n",
    "\n",
    "\n",
    "def getMatrizTFIDF():\n",
    "    \n",
    "    #Obtenemos cursorDoc, para realizar el calculo\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    \n",
    "    #Obtenemos tamaño del diccionario\n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "    \n",
    "    indiceInv = [0 for x in range(longDic)]\n",
    "    \n",
    "    cursorTF  = collMatrizTF.find()\n",
    "    for tf in cursorTF:     \n",
    "        cursorDen = collDenominador.find({\"_id\":{\"$in\":[tf['idword']]}})\n",
    "        for cur in cursorDen:                    \n",
    "            logTerm = math.log(cantDoc/cur['cantDocWord'])\n",
    "            tfidf = tf['cant']*logTerm           \n",
    "            #collTFIDF.insert_one({\"idDoc\":tf['idDoc'],\"idWord\":tf['idword'],\"tfidf\":tfidf})\n",
    "                        \n",
    "            if(tf['cant']>0):    \n",
    "                indiceInv[tf['idword']] = str(indiceInv[tf['idword']]) +\"|\"+str(tf['idDoc'])\n",
    "                \n",
    "    \n",
    "    for i in range(len(indiceInv)):\n",
    "        docs = indiceInv[i].split(\"|\")                \n",
    "        documentos=[]\n",
    "        for j in range(len(docs)):            \n",
    "            if(j>0):\n",
    "                documentos.append(docs[j])\n",
    "        #collIndIn.insert_one({\"idword\":i,\"documentos\":[documentos]})\n",
    "#getMatrizTFIDF()\n",
    "#print(\"Indice Invertido\")\n",
    "#col2 = collIndIn.find(\n",
    "#for cur2 in  col2:\n",
    "    #print(cur2)\n",
    "#print(\"Tfidf\")\n",
    "#col2 = collTFIDF.find()\n",
    "#for cur2 in  col2:\n",
    "#   print(cur2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de similitud de coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimilitudCoseno(VectorArchivo, vectorBusqueda):\n",
    "    x = np.array(VectorArchivo)\n",
    "    y = np.array(vectorBusqueda)\n",
    "    dot = np.dot(x,y)\n",
    "    x_modulus = np.sqrt((x*x).sum())\n",
    "    y_modulus = np.sqrt((y*y).sum())\n",
    "    similitud=0\n",
    "    if(x_modulus != 0 and y_modulus != 0 ):\n",
    "        similitud = dot / x_modulus / y_modulus\n",
    "    return similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir la funcion para realizar la busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar(cadena):   \n",
    "\n",
    "    cadena = cadena.lower()\n",
    "    cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "    for j in range(len(words)):             \n",
    "        cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)     \n",
    "   \n",
    "    resultadosBusqueda= []\n",
    "    listIdWords=[]\n",
    "    NumTerms=db.diccionario.count()\n",
    "    #cantidad de documentos\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    idDoc=[]\n",
    "    #Tomamos cada palabra ingresada en la busqueda\n",
    "    listaPalabras=Counter(cadena.split(\" \"))\n",
    "    vecBusqueda=np.zeros(NumTerms)\n",
    "    for WordF in listaPalabras.most_common():\n",
    "        num=WordF[1]  \n",
    "        findWord=db.diccionario.find_one({'word':WordF[0]})\n",
    "        if(findWord!= None):\n",
    "            IdWord=findWord['_id']\n",
    "            denom= collDenominador.find_one({\"_id\":{\"$in\":[IdWord]}})\n",
    "            valorDenom=denom['cantDocWord']\n",
    "            logTerm = math.log(cantDoc/valorDenom)\n",
    "            tfidfBusqueda=num*logTerm\n",
    "            vecBusqueda[IdWord]=tfidfBusqueda\n",
    "            if(num>0):\n",
    "                listIdWords.append(IdWord)\n",
    "    \n",
    "    tfidf=[]\n",
    "        \n",
    "    if(len(listIdWords)>0):\n",
    "        #Se busca con el indice invertido los documentos que tienen las palabras a buscar\n",
    "        IdDocuments= db.collectionindinv.find_one({'idword':listIdWords[0]})['documentos'][0]\n",
    "        for countWord in range(1,len(listIdWords)):\n",
    "            for IdDoc in db.collectionindinv.find_one({'idword':listIdWords[countWord]})['documentos'][0]:                   \n",
    "                if(IdDoc not in IdDocuments):\n",
    "                    IdDocuments.append(IdDoc)   \n",
    "     \n",
    "        countArchivos=0 \n",
    "        for IdDocument in IdDocuments:\n",
    "            VectorTfidf=[]\n",
    "            \n",
    "            for tfidfa in db.collectiontfidf.find({'idDoc':int(IdDocument)}):\n",
    "                \n",
    "                VectorTfidf.append(tfidfa['tfidf']) \n",
    "            resultadosBusqueda.append([])\n",
    "            similitud = SimilitudCoseno(VectorTfidf, vecBusqueda)\n",
    "           \n",
    "            resultadosBusqueda[countArchivos].append(IdDocument)\n",
    "            resultadosBusqueda[countArchivos].append(similitud)\n",
    "            countArchivos+=1\n",
    "        \n",
    "        resultadosBusqueda = sorted(resultadosBusqueda, key=lambda a_entry: a_entry[1],reverse=True)\n",
    "       \n",
    "        for resultado in resultadosBusqueda:\n",
    "           \n",
    "            idDoc=resultado[0]\n",
    "            docdb= db.raw.find_one({\"_id\": int(idDoc)})\n",
    "           \n",
    "            doc=docdb['documento']\n",
    "            docVec=doc.split(\"@@\")\n",
    "           \n",
    "            display(HTML('<h1>'+docVec[0]+'</h1>'))\n",
    "            display(HTML('<p>'+docVec[1]+'</p>'))\n",
    "       \n",
    "    # se imprime el diccionario\n",
    "    print(\"Se imprime el diccionario \")\n",
    "    dic = db.diccionario.find()\n",
    "    for cur2 in  dic:\n",
    "         print(cur2)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Función que lanza la ventana para el ingreso de las palabras a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>ITALY'S BNL TO ISSUE 120 MLN DLR CONVERTIBLE BOND</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Italy's state-owned <Banca Nazionale del\n",
       "Lavoro - BNL> said it would issue 120 mln dlrs of five-year\n",
       "convertible eurobonds, an operation to be lead-managed by\n",
       "<Credit Suisse-First Boston Ltd>.\n",
       "    BNL president Nerio Nesi told a news conference that the\n",
       "issue, to be placed on the main international markets and\n",
       "listed in Luxembourg, would be the first equity linked issue by\n",
       "an Italian bank on the Euromarket.\n",
       "    BNL officials said the issue is scheduled for mid-March and\n",
       "additional financial details were not immediately available.\n",
       "    They said the operation would be through the issue of\n",
       "depositary receipts by BNL's London branch. They said the bonds\n",
       "would carry warrants issued by its <Efibanca> subsidiary and\n",
       "convertible into BNL saving shares within five years.\n",
       "    The officials said a banking consortium led by Credit\n",
       "Suisse-First Boston would at the same time arrange for the\n",
       "private placing of an unspecified number of BNL savings shares\n",
       "with foreign institutional investors.\n",
       "    The operation was to further its aim of obtaining a listing\n",
       "on foreign stock exchanges with a view to future capital\n",
       "increases through ordinary share issues, they said.\n",
       " REUTER\n",
       "\u0003</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>NATIONAL FSI INC <NFSI> 4TH QTR LOSS</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Shr loss six cts vs profit 19 cts\n",
       "    Net loss 166,000 vs profit 580,000\n",
       "    Revs 3,772,000 vs 5,545,000\n",
       "    Year\n",
       "    Shr loss 13 cts vs profit 52 cts\n",
       "    Net loss 391,000 vs profit 1,425,000\n",
       "    Revs 15.4 mln vs 16.6 mln\n",
       "    NOTE: 1985 year figures pro forma for purchase accounting\n",
       "adjustments resulting from March 1985 reeacquisition of company\n",
       "by its original shareholders before August 1985 initial public\n",
       "offering. \n",
       " Reuter\n",
       "\u0003</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1><PRECAMBRIAN SHIELD RESOURCES LTD> YEAR LOSS</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Shr loss 1.93 dlrs vs profit 16 cts\n",
       "    Net loss 53,412,000 vs profit 4,479,000\n",
       "    Revs 24.8 mln vs 32.7 mln\n",
       "    Note: 1986 shr and net include 51,187,000 dlr writedown on\n",
       "U.S. operations, uneconomic coal operations and other mineral\n",
       "properties\n",
       " Reuter\n",
       "\u0003</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se imprime el diccionario \n",
      "{'_id': 0, 'word': 'accounting'}\n",
      "{'_id': 1, 'word': 'adjustments'}\n",
      "{'_id': 2, 'word': 'ag'}\n",
      "{'_id': 3, 'word': 'ago'}\n",
      "{'_id': 4, 'word': 'aim'}\n",
      "{'_id': 5, 'word': 'aircraft'}\n",
      "{'_id': 6, 'word': 'allowed'}\n",
      "{'_id': 7, 'word': 'amr'}\n",
      "{'_id': 8, 'word': 'announced'}\n",
      "{'_id': 9, 'word': 'appreciation'}\n",
      "{'_id': 10, 'word': 'arrange'}\n",
      "{'_id': 11, 'word': 'asked'}\n",
      "{'_id': 12, 'word': 'associations'}\n",
      "{'_id': 13, 'word': 'assumed'}\n",
      "{'_id': 14, 'word': 'august'}\n",
      "{'_id': 15, 'word': 'bank'}\n",
      "{'_id': 16, 'word': 'banking'}\n",
      "{'_id': 17, 'word': 'bnl'}\n",
      "{'_id': 18, 'word': 'bond'}\n",
      "{'_id': 19, 'word': 'boston'}\n",
      "{'_id': 20, 'word': 'business'}\n",
      "{'_id': 21, 'word': 'capital'}\n",
      "{'_id': 22, 'word': 'central'}\n",
      "{'_id': 23, 'word': 'chairman'}\n",
      "{'_id': 24, 'word': 'chang'}\n",
      "{'_id': 25, 'word': 'cheng'}\n",
      "{'_id': 26, 'word': 'chi'}\n",
      "{'_id': 27, 'word': 'chief'}\n",
      "{'_id': 28, 'word': 'coal'}\n",
      "{'_id': 29, 'word': 'commercial'}\n",
      "{'_id': 30, 'word': 'company'}\n",
      "{'_id': 31, 'word': 'consortium'}\n",
      "{'_id': 32, 'word': 'continued'}\n",
      "{'_id': 33, 'word': 'convertible'}\n",
      "{'_id': 34, 'word': 'credit'}\n",
      "{'_id': 35, 'word': 'currency'}\n",
      "{'_id': 36, 'word': 'davis'}\n",
      "{'_id': 37, 'word': 'deliveries'}\n",
      "{'_id': 38, 'word': 'details'}\n",
      "{'_id': 39, 'word': 'dlr'}\n",
      "{'_id': 40, 'word': 'dlrs'}\n",
      "{'_id': 41, 'word': 'dollar'}\n",
      "{'_id': 42, 'word': 'earlier'}\n",
      "{'_id': 43, 'word': 'early'}\n",
      "{'_id': 44, 'word': 'engines'}\n",
      "{'_id': 45, 'word': 'enter'}\n",
      "{'_id': 46, 'word': 'er'}\n",
      "{'_id': 47, 'word': 'exchange'}\n",
      "{'_id': 48, 'word': 'exchanges'}\n",
      "{'_id': 49, 'word': 'exporters'}\n",
      "{'_id': 50, 'word': 'fall'}\n",
      "{'_id': 51, 'word': 'february'}\n",
      "{'_id': 52, 'word': 'federation'}\n",
      "{'_id': 53, 'word': 'fertiliser'}\n",
      "{'_id': 54, 'word': 'figures'}\n",
      "{'_id': 55, 'word': 'firms'}\n",
      "{'_id': 56, 'word': 'fix'}\n",
      "{'_id': 57, 'word': 'foreign'}\n",
      "{'_id': 58, 'word': 'form'}\n",
      "{'_id': 59, 'word': 'forma'}\n",
      "{'_id': 60, 'word': 'fsi'}\n",
      "{'_id': 61, 'word': 'future'}\n",
      "{'_id': 62, 'word': 'ge'}\n",
      "{'_id': 63, 'word': 'given'}\n",
      "{'_id': 64, 'word': 'government'}\n",
      "{'_id': 65, 'word': 'governor'}\n",
      "{'_id': 66, 'word': 'halt'}\n",
      "{'_id': 67, 'word': 'herbicides'}\n",
      "{'_id': 68, 'word': 'hold'}\n",
      "{'_id': 69, 'word': 'hong'}\n",
      "{'_id': 70, 'word': 'include'}\n",
      "{'_id': 71, 'word': 'increases'}\n",
      "{'_id': 72, 'word': 'initial'}\n",
      "{'_id': 73, 'word': 'institutional'}\n",
      "{'_id': 74, 'word': 'intent'}\n",
      "{'_id': 75, 'word': 'investment'}\n",
      "{'_id': 76, 'word': 'investors'}\n",
      "{'_id': 77, 'word': 'issue'}\n",
      "{'_id': 78, 'word': 'issues'}\n",
      "{'_id': 79, 'word': 'italy'}\n",
      "{'_id': 80, 'word': 'joint'}\n",
      "{'_id': 81, 'word': 'kong'}\n",
      "{'_id': 82, 'word': 'korea'}\n",
      "{'_id': 83, 'word': 'largest'}\n",
      "{'_id': 84, 'word': 'led'}\n",
      "{'_id': 85, 'word': 'letter'}\n",
      "{'_id': 86, 'word': 'level'}\n",
      "{'_id': 87, 'word': 'listing'}\n",
      "{'_id': 88, 'word': 'local'}\n",
      "{'_id': 89, 'word': 'losing'}\n",
      "{'_id': 90, 'word': 'loss'}\n",
      "{'_id': 91, 'word': 'makers'}\n",
      "{'_id': 92, 'word': 'march'}\n",
      "{'_id': 93, 'word': 'midcon'}\n",
      "{'_id': 94, 'word': 'mineral'}\n",
      "{'_id': 95, 'word': 'ministry'}\n",
      "{'_id': 96, 'word': 'months'}\n",
      "{'_id': 97, 'word': 'national'}\n",
      "{'_id': 98, 'word': 'net'}\n",
      "{'_id': 99, 'word': 'note'}\n",
      "{'_id': 100, 'word': 'number'}\n",
      "{'_id': 101, 'word': 'obtaining'}\n",
      "{'_id': 102, 'word': 'occidental'}\n",
      "{'_id': 103, 'word': 'offering'}\n",
      "{'_id': 104, 'word': 'officer'}\n",
      "{'_id': 105, 'word': 'officials'}\n",
      "{'_id': 106, 'word': 'operating'}\n",
      "{'_id': 107, 'word': 'operation'}\n",
      "{'_id': 108, 'word': 'operations'}\n",
      "{'_id': 109, 'word': 'order'}\n",
      "{'_id': 110, 'word': 'orders'}\n",
      "{'_id': 111, 'word': 'ordinary'}\n",
      "{'_id': 112, 'word': 'original'}\n",
      "{'_id': 113, 'word': 'output'}\n",
      "{'_id': 114, 'word': 'owned'}\n",
      "{'_id': 115, 'word': 'pct'}\n",
      "{'_id': 116, 'word': 'placing'}\n",
      "{'_id': 117, 'word': 'planned'}\n",
      "{'_id': 118, 'word': 'plans'}\n",
      "{'_id': 119, 'word': 'plea'}\n",
      "{'_id': 120, 'word': 'president'}\n",
      "{'_id': 121, 'word': 'pressure'}\n",
      "{'_id': 122, 'word': 'private'}\n",
      "{'_id': 123, 'word': 'pro'}\n",
      "{'_id': 124, 'word': 'produce'}\n",
      "{'_id': 125, 'word': 'production'}\n",
      "{'_id': 126, 'word': 'profit'}\n",
      "{'_id': 127, 'word': 'properties'}\n",
      "{'_id': 128, 'word': 'public'}\n",
      "{'_id': 129, 'word': 'purchase'}\n",
      "{'_id': 130, 'word': 'qtr'}\n",
      "{'_id': 131, 'word': 'quoted'}\n",
      "{'_id': 132, 'word': 'rate'}\n",
      "{'_id': 133, 'word': 'reason'}\n",
      "{'_id': 134, 'word': 'received'}\n",
      "{'_id': 135, 'word': 'reeacquisition'}\n",
      "{'_id': 136, 'word': 'rejected'}\n",
      "{'_id': 137, 'word': 'rejects'}\n",
      "{'_id': 138, 'word': 'reponsibilities'}\n",
      "{'_id': 139, 'word': 'representatives'}\n",
      "{'_id': 140, 'word': 'request'}\n",
      "{'_id': 141, 'word': 'resigned'}\n",
      "{'_id': 142, 'word': 'resulting'}\n",
      "{'_id': 143, 'word': 'revs'}\n",
      "{'_id': 144, 'word': 'rise'}\n",
      "{'_id': 145, 'word': 'said'}\n",
      "{'_id': 146, 'word': 'sandoz'}\n",
      "{'_id': 147, 'word': 'saturday'}\n",
      "{'_id': 148, 'word': 'saving'}\n",
      "{'_id': 149, 'word': 'savings'}\n",
      "{'_id': 150, 'word': 'share'}\n",
      "{'_id': 151, 'word': 'shareholders'}\n",
      "{'_id': 152, 'word': 'shares'}\n",
      "{'_id': 153, 'word': 'signed'}\n",
      "{'_id': 154, 'word': 'singapore'}\n",
      "{'_id': 155, 'word': 'single'}\n",
      "{'_id': 156, 'word': 'size'}\n",
      "{'_id': 157, 'word': 'south'}\n",
      "{'_id': 158, 'word': 'soviet'}\n",
      "{'_id': 159, 'word': 'spokesman'}\n",
      "{'_id': 160, 'word': 'spokeswoman'}\n",
      "{'_id': 161, 'word': 'stake'}\n",
      "{'_id': 162, 'word': 'start'}\n",
      "{'_id': 163, 'word': 'state'}\n",
      "{'_id': 164, 'word': 'stock'}\n",
      "{'_id': 165, 'word': 'stop'}\n",
      "{'_id': 166, 'word': 'subsidiary'}\n",
      "{'_id': 167, 'word': 'suisse'}\n",
      "{'_id': 168, 'word': 'taiwan'}\n",
      "{'_id': 169, 'word': 'telling'}\n",
      "{'_id': 170, 'word': 'terpstra'}\n",
      "{'_id': 171, 'word': 'textile'}\n",
      "{'_id': 172, 'word': 'time'}\n",
      "{'_id': 173, 'word': 'today'}\n",
      "{'_id': 174, 'word': 'twinjets'}\n",
      "{'_id': 175, 'word': 'unable'}\n",
      "{'_id': 176, 'word': 'undertaken'}\n",
      "{'_id': 177, 'word': 'uneconomic'}\n",
      "{'_id': 178, 'word': 'union'}\n",
      "{'_id': 179, 'word': 'unspecified'}\n",
      "{'_id': 180, 'word': 'ussr'}\n",
      "{'_id': 181, 'word': 'venture'}\n",
      "{'_id': 182, 'word': 'ventures'}\n",
      "{'_id': 183, 'word': 'view'}\n",
      "{'_id': 184, 'word': 'weedkiller'}\n",
      "{'_id': 185, 'word': 'western'}\n",
      "{'_id': 186, 'word': 'william'}\n",
      "{'_id': 187, 'word': 'worth'}\n",
      "{'_id': 188, 'word': 'writedown'}\n",
      "{'_id': 189, 'word': 'year'}\n",
      "{'_id': 190, 'word': 'years'}\n",
      " ------ Tiempo de ejecucion 14.62304949760437 -----------\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#Generar la ventana que recibe el texto del buscador\n",
    "vent = Tk()\n",
    "a = StringVar()\n",
    "def valor():\n",
    "    a = entrada.get()    \n",
    "    buscar(a)\n",
    "\n",
    "entrada = Entry(vent, width=30)\n",
    "entrada.grid(row=0, column=0)\n",
    "\n",
    "boton = Button(vent, text=\"Buscar\", command=valor)\n",
    "boton.grid(row=1, column=0)\n",
    "\n",
    "vent.mainloop()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
