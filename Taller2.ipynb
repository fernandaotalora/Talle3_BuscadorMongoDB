{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto buscador de palabras con MongoDB Taller 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se lee el archivo inicial, se le quitan stopwords, caracteres especiales y se guarda en la base de datos en la coleccion documentos, la coleccion raw guarda los documentos como inicialmente se leen sin tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def conexionBD():\n",
    "    #Conexion a la base de datos\n",
    "    client = MongoClient()\n",
    "    client = pymongo.MongoClient(\"mongodb://testAdmin:12345@104.200.28.188:27017/buscador\")\n",
    "    db = client.buscadorTallerBigData2\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import bson\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from Documentos import Documentos\n",
    "from collections import Counter\n",
    "from Diccionario import Diccionario\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "db = conexionBD()\n",
    "#Obtenemos las colecciones para trabajar y guardar la informacion\n",
    "collDocumentos   = db.documentos\n",
    "collRaw          = db.raw\n",
    "collDic          = db.diccionario\n",
    "collMatrizTF     = db.matriztf\n",
    "collDenominador  = db.denominador\n",
    "collLogTermin    = db.logtermin\n",
    "\n",
    "#Obtenemos los stopwords\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close() \n",
    "\n",
    "def tomarDocumentos():\n",
    "    \n",
    "    pattern = re.compile(r'\\W+')\n",
    "\n",
    "    #Preparamos los datos a guardar, se utiliza el ejemplo de archivos\n",
    "    archivo = open(\"archivosinicial/reut2-001.sgm\", \"r\")\n",
    "    soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "    archivo.close()\n",
    "\n",
    "    documentos = []\n",
    "    documentos = soup1.find_all('reuters')\n",
    "    \n",
    "    #Obtener la informacion de los archivos\n",
    "    jsonDocumento = [0 for x in range(len(documentos))]\n",
    "    jsonRaw       = [0 for x in range(len(documentos))]\n",
    "\n",
    "\n",
    "    for i in range(len(documentos)):\n",
    "        try:        \n",
    "            cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "            cadena = cadena.lower()\n",
    "            cadena = cadena.replace(' reuter','')\n",
    "            cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "            for j in range(len(words)):             \n",
    "                cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)        \n",
    "            jsonDocumento[i] = Documentos(i,cadena)\n",
    "            cadena=documentos[i].title.string + \"@@\"+ documentos[i].body.string \n",
    "            jsonRaw[i] = Documentos(i,cadena)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # Guardamos los objetos documentos en la coleccion inicial    \n",
    "   #for doc in jsonDocumento:\n",
    "      #  collDocumentos.insert_one(doc.toDBCollection())\n",
    "\n",
    "    # Guardamos los objetos documentos en la coleccion raw    \n",
    "   # for doc in jsonRaw:    \n",
    "       # collRaw.insert_one(doc.toDBCollection())\n",
    "#tomarDocumentos()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda el diccionario en la base de datos en la coleccion diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDiccionario():\n",
    "    cadena =\"\"\n",
    "    cursor = collDocumentos.find()\n",
    "    for fut in cursor:\n",
    "        cadena = cadena+\" \"+fut['documento']\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    dictionary = pattern.split(cadena)\n",
    "    dictionary = sorted(list(set(dictionary)))\n",
    "    dictionary.remove(\"\")    \n",
    "\n",
    "    #se guarda el diccionario en la coleccion diccionario.\n",
    "    #for i in range(len(dictionary)):          \n",
    "       # idDic = collDic.insert_one({\"_id\":i,\"word\":dictionary[i]}).inserted_id    \n",
    "\n",
    "    #collDic.delete_one({\"_id\":'+str(i)+'})\n",
    "#getDiccionario()    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crear la matriztf y el denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF():\n",
    "    \n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "\n",
    "    denominador=[0 for x in range(longDic)]\n",
    "    \n",
    "    cursorDoc = collDocumentos.find()    \n",
    "    for fut in cursorDoc:            \n",
    "        cursorDic = collDic.find()\n",
    "        for dic in cursorDic:                                                 \n",
    "            patron = re.compile(r''+dic['word']+'')        \n",
    "            count = len(patron.findall(fut['documento']))            \n",
    "            #collMatrizTF.insert_one({\"idDoc\":fut['_id'],\"idword\":dic['_id'],\"cant\":count})\n",
    "            \n",
    "            if count > 0:                        \n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+1\n",
    "            else:\n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+0\n",
    "\n",
    "    \n",
    "    #for i in range(len(denominador)):\n",
    "        #collDenominador.insert_one({\"_id\":i,\"cantDocWord\":denominador[i]})        \n",
    "            \n",
    "#setMatrizTF()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crear la matriz tfidf e indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 0.3764004707336426 -----------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "collTFIDF = db.collectiontfidf\n",
    "collIndIn = db.collectionindinv\n",
    "\n",
    "\n",
    "def getMatrizTFIDF():\n",
    "    \n",
    "    #Obtenemos cursorDoc, para realizar el calculo\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    \n",
    "    #Obtenemos tamaÃ±o del diccionario\n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "    \n",
    "    indiceInv = [0 for x in range(longDic)]\n",
    "    \n",
    "    cursorTF  = collMatrizTF.find()\n",
    "    for tf in cursorTF:     \n",
    "        cursorDen = collDenominador.find({\"_id\":{\"$in\":[tf['idword']]}})\n",
    "        for cur in cursorDen:                    \n",
    "            logTerm = math.log(cantDoc/cur['cantDocWord'])\n",
    "            tfidf = tf['cant']*logTerm           \n",
    "            #collTFIDF.insert_one({\"idDoc\":tf['idDoc'],\"idWord\":tf['idword'],\"tfidf\":tfidf})\n",
    "                        \n",
    "            if(tf['cant']>0):    \n",
    "                indiceInv[tf['idword']] = str(indiceInv[tf['idword']]) +\"|\"+str(tf['idDoc'])\n",
    "                \n",
    "    \n",
    "    for i in range(len(indiceInv)):\n",
    "        docs = indiceInv[i].split(\"|\")                \n",
    "        documentos=[]\n",
    "        for j in range(len(docs)):            \n",
    "            if(j>0):\n",
    "                documentos.append(docs[j])\n",
    "        #collIndIn.insert_one({\"idword\":i,\"documentos\":[documentos]})\n",
    "#getMatrizTFIDF()\n",
    "#print(\"Indice Invertido\")\n",
    "#col2 = collIndIn.find(\n",
    "#for cur2 in  col2:\n",
    "    #print(cur2)\n",
    "#print(\"Tfidf\")\n",
    "#col2 = collTFIDF.find()\n",
    "#for cur2 in  col2:\n",
    "#   print(cur2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de similitud de coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimilitudCoseno(VectorArchivo, vectorBusqueda):\n",
    "    x = np.array(VectorArchivo)\n",
    "    y = np.array(vectorBusqueda)\n",
    "    dot = np.dot(x,y)\n",
    "    x_modulus = np.sqrt((x*x).sum())\n",
    "    y_modulus = np.sqrt((y*y).sum())\n",
    "    similitud=0\n",
    "    if(x_modulus != 0 and y_modulus != 0 ):\n",
    "        similitud = dot / x_modulus / y_modulus\n",
    "    return similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir la funcion para realizar la busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar(cadena):\n",
    "    # se imprime el diccionario\n",
    "    dic = db.diccionario.find()\n",
    "    for cur2 in  dic:\n",
    "         print(cur2)\n",
    "\n",
    "    cadena = cadena.lower()\n",
    "    cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "    for j in range(len(words)):             \n",
    "        cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)     \n",
    "   \n",
    "    resultadosBusqueda= []\n",
    "    listIdWords=[]\n",
    "    NumTerms=db.diccionario.count()\n",
    "    #cantidad de documentos\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    idDoc=[]\n",
    "    #Tomamos cada palabra ingresada en la busqueda\n",
    "    listaPalabras=Counter(cadena.split(\" \"))\n",
    "    vecBusqueda=np.zeros(NumTerms)\n",
    "    for WordF in listaPalabras.most_common():\n",
    "        num=WordF[1]  \n",
    "        findWord=db.diccionario.find_one({'word':WordF[0]})\n",
    "        if(findWord!= None):\n",
    "            IdWord=findWord['_id']\n",
    "            denom= collDenominador.find_one({\"_id\":{\"$in\":[IdWord]}})\n",
    "            valorDenom=denom['cantDocWord']\n",
    "            logTerm = math.log(cantDoc/valorDenom)\n",
    "            tfidfBusqueda=num*logTerm\n",
    "            vecBusqueda[IdWord]=tfidfBusqueda\n",
    "            if(num>0):\n",
    "                listIdWords.append(IdWord)\n",
    "    \n",
    "    tfidf=[]\n",
    "        \n",
    "    if(len(listIdWords)>0):\n",
    "        #Se busca con el indice invertido los documentos que tienen las palabras a buscar\n",
    "        IdDocuments= db.collectionindinv.find_one({'idword':listIdWords[0]})['documentos'][0]\n",
    "        for countWord in range(1,len(listIdWords)):\n",
    "            for IdDoc in db.collectionindinv.find_one({'idword':listIdWords[countWord]})['documentos'][0]:                   \n",
    "                if(IdDoc not in IdDocuments):\n",
    "                    IdDocuments.append(IdDoc)   \n",
    "     \n",
    "        countArchivos=0 \n",
    "        for IdDocument in IdDocuments:\n",
    "            VectorTfidf=[]\n",
    "            \n",
    "            for tfidfa in db.collectiontfidf.find({'idDoc':int(IdDocument)}):\n",
    "                \n",
    "                VectorTfidf.append(tfidfa['tfidf']) \n",
    "            resultadosBusqueda.append([])\n",
    "            similitud = SimilitudCoseno(VectorTfidf, vecBusqueda)\n",
    "           \n",
    "            resultadosBusqueda[countArchivos].append(IdDocument)\n",
    "            resultadosBusqueda[countArchivos].append(similitud)\n",
    "            countArchivos+=1\n",
    "        \n",
    "        resultadosBusqueda = sorted(resultadosBusqueda, key=lambda a_entry: a_entry[1],reverse=True)\n",
    "        clear_output()\n",
    "        for resultado in resultadosBusqueda:\n",
    "           \n",
    "            idDoc=resultado[0]\n",
    "            docdb= db.raw.find_one({\"_id\": int(idDoc)})\n",
    "           \n",
    "            doc=docdb['documento']\n",
    "            docVec=doc.split(\"@@\")\n",
    "           \n",
    "            display(HTML('<h1>'+docVec[0]+'</h1>'))\n",
    "            display(HTML('<p>'+docVec[1]+'</p>'))\n",
    "       \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>GE <GE> SAYS AMR <AMR> ORDER WORTH 650 MLN DLRS</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>General Electric Co said AMR\n",
       "Corp's oprder of GE CFG-80C2 engines to power 25 new <Airbus\n",
       "Industrie> A300-600R and 15 Boeing Co <BA> 767-300ER twinjets\n",
       "is worth over 650 mln dlrs.\n",
       "    The company said the order is the largest single one it has\n",
       "ever received for commercial aircraft engines.\n",
       "    AMR announced the order earlier today.\n",
       "    GE said deliveries will start in early 1988.\n",
       " Reuter\n",
       "\u0003</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>TAIWAN REJECTS TEXTILE MAKERS EXCHANGE RATE PLEA</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Central bank governor Chang Chi-cheng\n",
       "rejected a request by textile makers to halt the rise of the\n",
       "Taiwan dollar against the U.S. Dollar to stop them losing\n",
       "orders to South Korea, Hong Kong and Singapore, a spokesman for\n",
       "the Taiwan Textile Federation said.\n",
       "    He quoted Chang as telling representatives of 19 textile\n",
       "associations last Saturday the government could not fix the\n",
       "Taiwan dollar exchange rate at 35 to one U.S. Dollar due to\n",
       "U.S. Pressure for an appreciation of the local currency.\n",
       "    The Federation asked the government on February 19 to hold\n",
       "the exchange rate at that level.\n",
       "    The federation said in its request that many local textile\n",
       "exporters were operating without profit and would go out of\n",
       "business if the rate continued to fall.\n",
       " Reuter\n",
       "\u0003</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 14.260291814804077 -----------\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#Generar la ventana que recibe el texto del buscador\n",
    "vent = Tk()\n",
    "a = StringVar()\n",
    "def valor():\n",
    "    a = entrada.get()    \n",
    "    buscar(a)\n",
    "\n",
    "entrada = Entry(vent, width=30)\n",
    "entrada.grid(row=0, column=0)\n",
    "\n",
    "boton = Button(vent, text=\"Buscar\", command=valor)\n",
    "boton.grid(row=1, column=0)\n",
    "\n",
    "vent.mainloop()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
