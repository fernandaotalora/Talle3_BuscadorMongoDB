{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Proyecto buscador de palabras con MongoDB Taller 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee el archivo inicial, se le quitan stopwords, caracteres especiales y se guarda en la base de datos en la coleccion documentos, la coleccion raw guarda los documentos como inicialmente se leen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def conexionBD():\n",
    "    #Conexion a la base de datos\n",
    "    client = MongoClient()\n",
    "    client = pymongo.MongoClient(\"mongodb://testAdmin:12345@104.200.28.188:27017/buscador\")\n",
    "    db = client.buscador\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import bson\n",
    "import collections\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from Documentos import Documentos\n",
    "from Diccionario import Diccionario\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "db = conexionBD()\n",
    "#Obtenemos las colecciones para trabajar y guardar la informacion\n",
    "collDocumentos   = db.documentos\n",
    "collRaw          = db.raw\n",
    "collDic          = db.diccionario\n",
    "collMatrizTF     = db.matriztf\n",
    "collDenominador  = db.denominador\n",
    "\n",
    "#Obtenemos los stopwords\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close() \n",
    "\n",
    "def tomarDocumentos():\n",
    "    \n",
    "    pattern = re.compile(r'\\W+')\n",
    "\n",
    "    #Preparamos los datos a guardar, se utiliza el ejemplo de archivos\n",
    "    archivo = open(\"archivosinicial/reut2-001.sgm\", \"r\")\n",
    "    soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "    archivo.close()\n",
    "\n",
    "    documentos = []\n",
    "    documentos = soup1.find_all('reuters')\n",
    "    \n",
    "    #Obtener la informacion de los archivos\n",
    "    jsonDocumento = [0 for x in range(len(documentos))]\n",
    "    jsonRaw       = [0 for x in range(len(documentos))]\n",
    "\n",
    "\n",
    "    for i in range(len(documentos)):\n",
    "        try:        \n",
    "            cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "            cadena = cadena.lower()\n",
    "            cadena = cadena.replace(' reuter','')\n",
    "            cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "            for j in range(len(words)):             \n",
    "                cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)        \n",
    "            jsonDocumento[i] = Documentos(i,cadena)\n",
    "            cadena=documentos[i].title.string + \" \"+ documentos[i].body.string \n",
    "            jsonRaw[i] = Documentos(i,cadena)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # Guardamos los objetos documentos en la coleccion inicial    \n",
    "    #for doc in jsonDocumento:\n",
    "        #collDocumentos.insert_one(doc.toDBCollection())\n",
    "\n",
    "    # Guardamos los objetos documentos en la coleccion raw    \n",
    "    #for doc in jsonRaw:    \n",
    "        #collRaw.insert_one(doc.toDBCollection())\n",
    "#tomarDocumentos()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda el diccionario en la base de datos en la coleccion diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDiccionario():\n",
    "    cadena =\"\"\n",
    "    cursor = collDocumentos.find()\n",
    "    for fut in cursor:\n",
    "        cadena = cadena+\" \"+fut['documento']\n",
    "\n",
    "    dictionary = pattern.split(cadena)\n",
    "    dictionary = sorted(list(set(dictionary)))\n",
    "    dictionary.remove(\"\")    \n",
    "\n",
    "    #se guarda el diccionario en la coleccion diccionario.\n",
    "    #for i in range(len(dictionary)):          \n",
    "      #  idDic = collDic.insert_one({\"_id\":i,\"word\":dictionary[i]}).inserted_id    \n",
    "\n",
    "    #collDic.delete_one({\"_id\":'+str(i)+'})\n",
    "#getDiccionario()    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crear la matriztf y el denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF():\n",
    "    \n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "\n",
    "    denominador=[0 for x in range(longDic)]\n",
    "    \n",
    "    cursorDoc = collDocumentos.find()    \n",
    "    for fut in cursorDoc:            \n",
    "        cursorDic = collDic.find()\n",
    "        for dic in cursorDic:                                                 \n",
    "            patron = re.compile(r''+dic['word']+'')        \n",
    "            count = len(patron.findall(fut['documento']))            \n",
    "            #collMatrizTF.insert_one({\"idDoc\":fut['_id'],\"idword\":dic['_id'],\"cant\":count})\n",
    "            \n",
    "            if count > 0:                        \n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+1\n",
    "            else:\n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+0\n",
    "\n",
    "    \n",
    "    #for i in range(len(denominador)):\n",
    "        #collDenominador.insert_one({\"_id\":i,\"cantDocWord\":denominador[i]})        \n",
    "            \n",
    "#setMatrizTF()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crear la matriz tfidf e indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 0.33002209663391113 -----------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "collTFIDF = db.collectiontfidf\n",
    "collIndIn = db.collectionindinv\n",
    "\n",
    "\n",
    "def getMatrizTFIDF():\n",
    "    \n",
    "    #Obtenemos D, para realizar el calculo\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    \n",
    "    #Obtenemos tamaÃ±o del diccionario\n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "    \n",
    "    indiceInv = [0 for x in range(longDic)]\n",
    "    \n",
    "    cursorTF  = collMatrizTF.find()\n",
    "    for tf in cursorTF:        \n",
    "        \n",
    "        cursorDen = collDenominador.find({\"_id\":{\"$in\":[tf['idword']]}})\n",
    "        for cur in cursorDen:\n",
    "                    \n",
    "            logTerm = math.log(cantDoc/cur['cantDocWord'])\n",
    "            tfidf = tf['cant']*logTerm\n",
    "            \n",
    "            #collTFIDF.insert_one({\"idDoc\":tf['idDoc'],\"idWord\":tf['idword'],\"tfidf\":tfidf})\n",
    "                        \n",
    "            if(tf['cant']>0):    \n",
    "                indiceInv[tf['idword']] = str(indiceInv[tf['idword']]) +\"|\"+str(tf['idDoc'])\n",
    "                \n",
    "    \n",
    "    for i in range(len(indiceInv)):\n",
    "        docs = indiceInv[i].split(\"|\")                \n",
    "        documentos=[]\n",
    "        for j in range(len(docs)):            \n",
    "            if(j>0):\n",
    "                documentos.append(docs[j])\n",
    "        collIndIn.insert_one({\"idword\":i,\"documentos\":[documentos]})\n",
    "#getMatrizTFIDF()\n",
    "\n",
    "#collIndIn.delete_one({\"idword\":190})    \n",
    "\n",
    "\n",
    "#print(\"Indice Invertido\")\n",
    "#col2 = collIndIn.find()\n",
    "#for cur2 in  col2:\n",
    "    #print(cur2)\n",
    "    \n",
    "#print(\"Tfidf\")\n",
    "#col2 = collTFIDF.find()\n",
    "#for cur2 in  col2:\n",
    "    #print(cur2)\n",
    "\n",
    "    \n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion de similitud de coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimilitudCoseno(VectorArchivo, vectorBusqueda):\n",
    "    x = np.array(VectorArchivo)\n",
    "    y = np.array(vectorBusqueda)\n",
    "    dot = np.dot(x,y)\n",
    "    x_modulus = np.sqrt((x*x).sum())\n",
    "    y_modulus = np.sqrt((y*y).sum())\n",
    "    similitud=0\n",
    "    if(x_modulus != 0 and y_modulus != 0 ):\n",
    "        similitud = dot / x_modulus / y_modulus\n",
    "    return similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la funcion para realizar la busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar(cadena):\n",
    "    cadena = cadena.lower()\n",
    "    cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "    for j in range(len(words)):             \n",
    "        cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)     \n",
    "\n",
    "    pattern = re.compile(r'\\W+')    \n",
    "    wordsSearch  = pattern.split(cadena)         \n",
    "    \n",
    "    cursor = collDic.find()\n",
    "    for dic in cursor:\n",
    "        print(dic)\n",
    "    w=cursor.count()    \n",
    "    vector = [0 for x in range(w)]    \n",
    "    \n",
    "    for i in range(len(wordsSearch)):\n",
    "        try:            \n",
    "            ind = collDic.find({\"word\":{\"$in\":[wordsSearch[i]]}})            \n",
    "            for j in ind:\n",
    "                print(j['_id'])\n",
    "                if(vector[j['_id']]>0):\n",
    "                    vector[j['_id']] = vector[j['_id']]+1\n",
    "                else:    \n",
    "                    vector[j['_id']] = 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 0, 'word': 'accounting'}\n",
      "{'_id': 1, 'word': 'adjustments'}\n",
      "{'_id': 2, 'word': 'ag'}\n",
      "{'_id': 3, 'word': 'ago'}\n",
      "{'_id': 4, 'word': 'aim'}\n",
      "{'_id': 5, 'word': 'aircraft'}\n",
      "{'_id': 6, 'word': 'allowed'}\n",
      "{'_id': 7, 'word': 'amr'}\n",
      "{'_id': 8, 'word': 'announced'}\n",
      "{'_id': 9, 'word': 'appreciation'}\n",
      "{'_id': 10, 'word': 'arrange'}\n",
      "{'_id': 11, 'word': 'asked'}\n",
      "{'_id': 12, 'word': 'associations'}\n",
      "{'_id': 13, 'word': 'assumed'}\n",
      "{'_id': 14, 'word': 'august'}\n",
      "{'_id': 15, 'word': 'bank'}\n",
      "{'_id': 16, 'word': 'banking'}\n",
      "{'_id': 17, 'word': 'bnl'}\n",
      "{'_id': 18, 'word': 'bond'}\n",
      "{'_id': 19, 'word': 'boston'}\n",
      "{'_id': 20, 'word': 'business'}\n",
      "{'_id': 21, 'word': 'capital'}\n",
      "{'_id': 22, 'word': 'central'}\n",
      "{'_id': 23, 'word': 'chairman'}\n",
      "{'_id': 24, 'word': 'chang'}\n",
      "{'_id': 25, 'word': 'cheng'}\n",
      "{'_id': 26, 'word': 'chi'}\n",
      "{'_id': 27, 'word': 'chief'}\n",
      "{'_id': 28, 'word': 'coal'}\n",
      "{'_id': 29, 'word': 'commercial'}\n",
      "{'_id': 30, 'word': 'company'}\n",
      "{'_id': 31, 'word': 'consortium'}\n",
      "{'_id': 32, 'word': 'continued'}\n",
      "{'_id': 33, 'word': 'convertible'}\n",
      "{'_id': 34, 'word': 'credit'}\n",
      "{'_id': 35, 'word': 'currency'}\n",
      "{'_id': 36, 'word': 'davis'}\n",
      "{'_id': 37, 'word': 'deliveries'}\n",
      "{'_id': 38, 'word': 'details'}\n",
      "{'_id': 39, 'word': 'dlr'}\n",
      "{'_id': 40, 'word': 'dlrs'}\n",
      "{'_id': 41, 'word': 'dollar'}\n",
      "{'_id': 42, 'word': 'earlier'}\n",
      "{'_id': 43, 'word': 'early'}\n",
      "{'_id': 44, 'word': 'engines'}\n",
      "{'_id': 45, 'word': 'enter'}\n",
      "{'_id': 46, 'word': 'er'}\n",
      "{'_id': 47, 'word': 'exchange'}\n",
      "{'_id': 48, 'word': 'exchanges'}\n",
      "{'_id': 49, 'word': 'exporters'}\n",
      "{'_id': 50, 'word': 'fall'}\n",
      "{'_id': 51, 'word': 'february'}\n",
      "{'_id': 52, 'word': 'federation'}\n",
      "{'_id': 53, 'word': 'fertiliser'}\n",
      "{'_id': 54, 'word': 'figures'}\n",
      "{'_id': 55, 'word': 'firms'}\n",
      "{'_id': 56, 'word': 'fix'}\n",
      "{'_id': 57, 'word': 'foreign'}\n",
      "{'_id': 58, 'word': 'form'}\n",
      "{'_id': 59, 'word': 'forma'}\n",
      "{'_id': 60, 'word': 'fsi'}\n",
      "{'_id': 61, 'word': 'future'}\n",
      "{'_id': 62, 'word': 'ge'}\n",
      "{'_id': 63, 'word': 'given'}\n",
      "{'_id': 64, 'word': 'government'}\n",
      "{'_id': 65, 'word': 'governor'}\n",
      "{'_id': 66, 'word': 'halt'}\n",
      "{'_id': 67, 'word': 'herbicides'}\n",
      "{'_id': 68, 'word': 'hold'}\n",
      "{'_id': 69, 'word': 'hong'}\n",
      "{'_id': 70, 'word': 'include'}\n",
      "{'_id': 71, 'word': 'increases'}\n",
      "{'_id': 72, 'word': 'initial'}\n",
      "{'_id': 73, 'word': 'institutional'}\n",
      "{'_id': 74, 'word': 'intent'}\n",
      "{'_id': 75, 'word': 'investment'}\n",
      "{'_id': 76, 'word': 'investors'}\n",
      "{'_id': 77, 'word': 'issue'}\n",
      "{'_id': 78, 'word': 'issues'}\n",
      "{'_id': 79, 'word': 'italy'}\n",
      "{'_id': 80, 'word': 'joint'}\n",
      "{'_id': 81, 'word': 'kong'}\n",
      "{'_id': 82, 'word': 'korea'}\n",
      "{'_id': 83, 'word': 'largest'}\n",
      "{'_id': 84, 'word': 'led'}\n",
      "{'_id': 85, 'word': 'letter'}\n",
      "{'_id': 86, 'word': 'level'}\n",
      "{'_id': 87, 'word': 'listing'}\n",
      "{'_id': 88, 'word': 'local'}\n",
      "{'_id': 89, 'word': 'losing'}\n",
      "{'_id': 90, 'word': 'loss'}\n",
      "{'_id': 91, 'word': 'makers'}\n",
      "{'_id': 92, 'word': 'march'}\n",
      "{'_id': 93, 'word': 'midcon'}\n",
      "{'_id': 94, 'word': 'mineral'}\n",
      "{'_id': 95, 'word': 'ministry'}\n",
      "{'_id': 96, 'word': 'months'}\n",
      "{'_id': 97, 'word': 'national'}\n",
      "{'_id': 98, 'word': 'net'}\n",
      "{'_id': 99, 'word': 'note'}\n",
      "{'_id': 100, 'word': 'number'}\n",
      "{'_id': 101, 'word': 'obtaining'}\n",
      "{'_id': 102, 'word': 'occidental'}\n",
      "{'_id': 103, 'word': 'offering'}\n",
      "{'_id': 104, 'word': 'officer'}\n",
      "{'_id': 105, 'word': 'officials'}\n",
      "{'_id': 106, 'word': 'operating'}\n",
      "{'_id': 107, 'word': 'operation'}\n",
      "{'_id': 108, 'word': 'operations'}\n",
      "{'_id': 109, 'word': 'order'}\n",
      "{'_id': 110, 'word': 'orders'}\n",
      "{'_id': 111, 'word': 'ordinary'}\n",
      "{'_id': 112, 'word': 'original'}\n",
      "{'_id': 113, 'word': 'output'}\n",
      "{'_id': 114, 'word': 'owned'}\n",
      "{'_id': 115, 'word': 'pct'}\n",
      "{'_id': 116, 'word': 'placing'}\n",
      "{'_id': 117, 'word': 'planned'}\n",
      "{'_id': 118, 'word': 'plans'}\n",
      "{'_id': 119, 'word': 'plea'}\n",
      "{'_id': 120, 'word': 'president'}\n",
      "{'_id': 121, 'word': 'pressure'}\n",
      "{'_id': 122, 'word': 'private'}\n",
      "{'_id': 123, 'word': 'pro'}\n",
      "{'_id': 124, 'word': 'produce'}\n",
      "{'_id': 125, 'word': 'production'}\n",
      "{'_id': 126, 'word': 'profit'}\n",
      "{'_id': 127, 'word': 'properties'}\n",
      "{'_id': 128, 'word': 'public'}\n",
      "{'_id': 129, 'word': 'purchase'}\n",
      "{'_id': 130, 'word': 'qtr'}\n",
      "{'_id': 131, 'word': 'quoted'}\n",
      "{'_id': 132, 'word': 'rate'}\n",
      "{'_id': 133, 'word': 'reason'}\n",
      "{'_id': 134, 'word': 'received'}\n",
      "{'_id': 135, 'word': 'reeacquisition'}\n",
      "{'_id': 136, 'word': 'rejected'}\n",
      "{'_id': 137, 'word': 'rejects'}\n",
      "{'_id': 138, 'word': 'reponsibilities'}\n",
      "{'_id': 139, 'word': 'representatives'}\n",
      "{'_id': 140, 'word': 'request'}\n",
      "{'_id': 141, 'word': 'resigned'}\n",
      "{'_id': 142, 'word': 'resulting'}\n",
      "{'_id': 143, 'word': 'revs'}\n",
      "{'_id': 144, 'word': 'rise'}\n",
      "{'_id': 145, 'word': 'said'}\n",
      "{'_id': 146, 'word': 'sandoz'}\n",
      "{'_id': 147, 'word': 'saturday'}\n",
      "{'_id': 148, 'word': 'saving'}\n",
      "{'_id': 149, 'word': 'savings'}\n",
      "{'_id': 150, 'word': 'share'}\n",
      "{'_id': 151, 'word': 'shareholders'}\n",
      "{'_id': 152, 'word': 'shares'}\n",
      "{'_id': 153, 'word': 'signed'}\n",
      "{'_id': 154, 'word': 'singapore'}\n",
      "{'_id': 155, 'word': 'single'}\n",
      "{'_id': 156, 'word': 'size'}\n",
      "{'_id': 157, 'word': 'south'}\n",
      "{'_id': 158, 'word': 'soviet'}\n",
      "{'_id': 159, 'word': 'spokesman'}\n",
      "{'_id': 160, 'word': 'spokeswoman'}\n",
      "{'_id': 161, 'word': 'stake'}\n",
      "{'_id': 162, 'word': 'start'}\n",
      "{'_id': 163, 'word': 'state'}\n",
      "{'_id': 164, 'word': 'stock'}\n",
      "{'_id': 165, 'word': 'stop'}\n",
      "{'_id': 166, 'word': 'subsidiary'}\n",
      "{'_id': 167, 'word': 'suisse'}\n",
      "{'_id': 168, 'word': 'taiwan'}\n",
      "{'_id': 169, 'word': 'telling'}\n",
      "{'_id': 170, 'word': 'terpstra'}\n",
      "{'_id': 171, 'word': 'textile'}\n",
      "{'_id': 172, 'word': 'time'}\n",
      "{'_id': 173, 'word': 'today'}\n",
      "{'_id': 174, 'word': 'twinjets'}\n",
      "{'_id': 175, 'word': 'unable'}\n",
      "{'_id': 176, 'word': 'undertaken'}\n",
      "{'_id': 177, 'word': 'uneconomic'}\n",
      "{'_id': 178, 'word': 'union'}\n",
      "{'_id': 179, 'word': 'unspecified'}\n",
      "{'_id': 180, 'word': 'ussr'}\n",
      "{'_id': 181, 'word': 'venture'}\n",
      "{'_id': 182, 'word': 'ventures'}\n",
      "{'_id': 183, 'word': 'view'}\n",
      "{'_id': 184, 'word': 'weedkiller'}\n",
      "{'_id': 185, 'word': 'western'}\n",
      "{'_id': 186, 'word': 'william'}\n",
      "{'_id': 187, 'word': 'worth'}\n",
      "{'_id': 188, 'word': 'writedown'}\n",
      "{'_id': 189, 'word': 'year'}\n",
      "{'_id': 190, 'word': 'years'}\n",
      "<pymongo.cursor.Cursor object at 0x000000AC4FD4AB38>\n",
      "49\n",
      "<pymongo.cursor.Cursor object at 0x000000AC506D8EB8>\n",
      "106\n",
      "<pymongo.cursor.Cursor object at 0x000000AC50386470>\n",
      "126\n",
      "<pymongo.cursor.Cursor object at 0x000000AC50386D68>\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " ------ Tiempo de ejecucion 81.94328570365906 -----------\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#Generar la ventana que recibe el texto del buscador\n",
    "vent = Tk()\n",
    "a = StringVar()\n",
    "\n",
    "\n",
    "def valor():\n",
    "    a = entrada.get()    \n",
    "    buscar(a)\n",
    "\n",
    "entrada = Entry(vent, width=30)\n",
    "entrada.grid(row=0, column=0)\n",
    "\n",
    "boton = Button(vent, text=\"Buscar\", command=valor)\n",
    "boton.grid(row=1, column=0)\n",
    "\n",
    "vent.mainloop()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
