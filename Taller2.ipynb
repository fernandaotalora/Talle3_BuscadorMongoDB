{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Proyecto buscador de palabras con MongoDB Taller 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee el archivo inicial, se le quitan stopwords, caracteres especiales y se guarda en la base de datos en la coleccion documentos, la coleccion raw guarda los documentos como inicialmente se leen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import bson\n",
    "import collections\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from Documentos import Documentos\n",
    "from Diccionario import Diccionario\n",
    "\n",
    "\n",
    "#Conexion a la base de datos\n",
    "client = MongoClient()\n",
    "client = pymongo.MongoClient(\"mongodb://testAdmin:12345@104.200.28.188:27017/buscador\")\n",
    "db = client.buscador\n",
    "\n",
    "pattern = re.compile(r'\\W+')\n",
    "\n",
    "#Preparamos los datos a guardar, se utiliza el ejemplo de archivos\n",
    "archivo = open(\"archivosinicial/reut2-001.sgm\", \"r\")\n",
    "soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "archivo.close()\n",
    "\n",
    "documentos = []\n",
    "documentos = soup1.find_all('reuters')\n",
    "\n",
    "#Obtenemos los stopwords\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close()\n",
    "\n",
    "#Obtenemos las colecciones para trabajar y guardar la informacion\n",
    "collDocumentos   = db.documentos\n",
    "collRaw          = db.raw\n",
    "collDic          = db.diccionario\n",
    "collMatrizTF     = db.matriztf\n",
    "collDenominador  = db.denominador\n",
    "\n",
    "#Obtener la informacion de los archivos\n",
    "jsonDocumento = [0 for x in range(len(documentos))]\n",
    "jsonRaw       = [0 for x in range(len(documentos))]\n",
    "\n",
    "\n",
    "for i in range(len(documentos)):\n",
    "    try:        \n",
    "        cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "        cadena = cadena.lower()\n",
    "        cadena = cadena.replace(' reuter','')\n",
    "        cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)\n",
    "        for j in range(len(words)):             \n",
    "            cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)        \n",
    "        jsonDocumento[i] = Documentos(i,cadena)\n",
    "        cadena=documentos[i].title.string + \" \"+ documentos[i].body.string \n",
    "        jsonRaw[i] = Documentos(i,cadena)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "# Guardamos los objetos documentos en la coleccion inicial    \n",
    "#for doc in jsonDocumento:\n",
    "    #collDocumentos.insert_one(doc.toDBCollection())\n",
    "\n",
    "# Guardamos los objetos documentos en la coleccion raw    \n",
    "#for doc in jsonRaw:    \n",
    "    #collRaw.insert_one(doc.toDBCollection())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda el diccionario en la base de datos en la coleccion diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena =\"\"\n",
    "cursor = collDocumentos.find()\n",
    "for fut in cursor:\n",
    "    cadena = cadena+\" \"+fut['documento']\n",
    "\n",
    "dictionary = pattern.split(cadena)\n",
    "dictionary = sorted(list(set(dictionary)))\n",
    "dictionary.remove(\"\")    \n",
    "\n",
    "#se guarda el diccionario en la coleccion diccionario.\n",
    "#for i in range(len(dictionary)):          \n",
    "  #  idDic = collDic.insert_one({\"_id\":i,\"word\":dictionary[i]}).inserted_id    \n",
    "\n",
    "#collDic.delete_one({\"_id\":'+str(i)+'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crear la matriztf y el denominador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF():\n",
    "    \n",
    "    cursorDic = collDic.find()\n",
    "    longDic=cursorDic.count()\n",
    "\n",
    "    denominador=[0 for x in range(longDic)]\n",
    "    \n",
    "    cursorDoc = collDocumentos.find()    \n",
    "    for fut in cursorDoc:            \n",
    "        cursorDic = collDic.find()\n",
    "        for dic in cursorDic:                                                 \n",
    "            patron = re.compile(r''+dic['word']+'')        \n",
    "            count = len(patron.findall(fut['documento']))            \n",
    "            #collMatrizTF.insert_one({\"idDoc\":fut['_id'],\"idword\":dic['_id'],\"cant\":count})\n",
    "            \n",
    "            if count > 0:                        \n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+1\n",
    "            else:\n",
    "                denominador[dic['_id']]=denominador[dic['_id']]+0\n",
    "\n",
    "    \n",
    "    #for i in range(len(denominador)):\n",
    "        #collDenominador.insert_one({\"_id\":i,\"cantDocWord\":denominador[i]})        \n",
    "            \n",
    "setMatrizTF()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crear la matriz tfidf e indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "collTFIDF = db.collectiontfidf\n",
    "collIndIn = db.collectionindinv\n",
    "\n",
    "def getMatrizTFIDF():\n",
    "    \n",
    "    #D\n",
    "    cursorDoc = collDocumentos.find()\n",
    "    cantDoc=cursorDoc.count()\n",
    "    \n",
    "    cursorTF  = collMatrizTF.find()\n",
    "    for tf in cursorTF:        \n",
    "        nq = []\n",
    "        \n",
    "        tf['idWord']\n",
    "        tf['cant']\n",
    "        \n",
    "        cursorDen = collDenominador.find({\"_id\":{\"$in\":[0]}})\n",
    "        for cur in cursorDen:\n",
    "            print(str(cur['_id'])+\" \"+str(cur['cantDocWord']))\n",
    "            \n",
    "            logTerm = math.log(cantDoc/cur['cantDocWord'])\n",
    "            tfidf = tf['cant']*logTerm\n",
    "            \n",
    "            collTFIDF.insert_one({\"_id\":tf['_id'],\"idWord\":tf['idWord'],\"tfidf\":tfidf})\n",
    "            if(tfidf>0):    \n",
    "                \n",
    "        for j in range(len(doc)): \n",
    "\n",
    "            if i==0:\n",
    "                InvertedIndex.append([])\n",
    "                logTerm.append([])\n",
    "                logTerm[j]=math.log(h/int(denominador[j]))\n",
    "                tfidf= int(doc[j])*logTerm[j]\n",
    "                if(tfidf>0):\n",
    "                    nq.append([j,tfidf])\n",
    "            else:\n",
    "                tfidf = int(doc[j])*logTerm[j]\n",
    "                if(tfidf>0):\n",
    "                    nq.append([j,tfidf])\n",
    "            if(tfidf>0):\n",
    "                InvertedIndex[j].append(i)\n",
    "                \n",
    "        TFIDFDb.append( {\"id\":i,\"tf_idf\":nq} )\n",
    "    \n",
    "    print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))   \n",
    "   \n",
    "         \n",
    "\n",
    "getMatrizTFIDF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
